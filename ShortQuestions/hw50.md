3.
Resiliency patterns are a type of service architecture that help to prevent cascading failures and to preserve functionality in the event of service failure. Common resiliency patterns used in application development include the bulkhead pattern and circuit breaker pattern.

A circuit breaker is a pattern designed to prevent a cascade of failures in a distributed system. When a service call fails a number of times, the circuit breaker trips, and further attempts to invoke the service will fail immediately without the call being made

4.
1). Write main features of Microservices:
Decoupling: Within a system, services are largely decoupled. The application as a whole can therefore be easily constructed, altered, and scalable
Componentization: Microservices are viewed as independent components that can easily be exchanged or upgraded
Business Capabilities: Microservices are relatively simple and only focus on one service
Team autonomy: Each developer works independently of each other, allowing for a faster project timeline
Continuous Delivery: Enables frequent software releases through systematic automation of software development, testing, and approval
Responsibility: Microservices are not focused on applications as projects. Rather, they see applications as products they are responsible for
Decentralized Governance: Choosing the right tool according to the job is the goal. Developers can choose the best tools to solve their problems
Agility: Microservices facilitate agile development. It is possible to create new features quickly and discard them again at any time.

2).Write main components of Microservices.
Some of the main components of microservices include: 
Containers, Clustering, and Orchestration 
IaC [Infrastructure as Code Conception] 
Cloud Infrastructure 
API Gateway 
Enterprise Service Bus 
Service Delivery 

3).What is the role of actuator in spring boot?
A spring boot actuator is a project that provides restful web services to access the current state of an application that is running in production. In addition, you can monitor and manage application usage in a production environment without having to code or configure any of the applications.

4).Explain spring cloud and spring boot.
Spring Cloud: In Microservices, the Spring cloud is a system that integrates with external systems. This is a short-lived framework designed to build applications quickly. It contributes significantly to microservice architecture due to its association with finite amounts of data processing. 
Spring Boot: Spring Boot is an open-sourced, Java-based framework that provides its developers with a platform on which they can create stand-alone, production-grade Spring applications. In addition to reducing development time and increasing productivity, it is easily understood.  


5.
Load Balancing Algorithms
Round Robin: Requests are distributed across the group of servers sequentially.
Least Connections: Requests are sent to the server with the fewest active connections.
IP Hash: A hash of the client’s IP address is used to determine which server receives the request, ensuring the same client always reaches the same server if it’s available.
Random with Weighting: Requests are distributed randomly, but servers with higher capacity get a larger share of the traffic.

Implementing Load Balancing
DNS Load Balancing
DNS-based load balancing distributes requests at the domain name system (DNS) level.
When a DNS lookup is performed, it returns IP addresses in different orders to balance the load.
This method is straightforward but lacks granularity and immediate health checks of services.
Hardware Load Balancers
Physical appliances can be used in data centers to distribute traffic.
They are usually reliable and high-performance but can be costly and lack the flexibility required for dynamic microservice environments.
Software Load Balancers
Software solutions are more flexible and can be run on commodity hardware or in the cloud.
Tools like HAProxy provide high availability, load balancing, and proxying for TCP and HTTP applications.

6.
Client-Side Discovery: In this pattern, the client service is responsible for determining the network locations of available service instances and load balancing requests across them. The client queries a service registry, gets a list of available service instances, and uses a load-balancing algorithm to select one.

Server-Side Discovery: Here, a server (often a dedicated load balancer) is responsible for service discovery. The client makes a request to the load balancer, which then queries the service registry and forwards the request to an available service instance.


7.
Broker: A Kafka broker is a single Kafka server that forms part of the Kafka cluster. Brokers are responsible for maintaining published data. Each broker can handle terabytes of messages without performance impact.

Producer: Producers are the clients or processes that publish (write) messages to Kafka. They send data to topics within the broker.

Consumer: Consumers are the clients or processes that subscribe to topics and read messages from brokers. Consumers can be part of a consumer group to share the processing of data.

Topic: A topic is a category or feed name to which messages are published. Topics in Kafka are multi-subscriber; that is, a topic can have zero, one, or many consumers that subscribe to the data written to it.

Partition: Topics are split into partitions, which are ordered, immutable sequences of messages. Partitions allow the parallel processing of data. Each partition is an ordered, immutable sequence of messages that is continually appended to—a commit log.

Offset: Kafka assigns a sequential ID number to each message in a partition, called an offset. Offsets are unique to each partition within a topic and provide a way for consumers to keep track of their position (which messages have been consumed).

Replica: Replicas are copies of partitions for redundancy and failover. Kafka replicates the log for each topic's partitions across a configurable number of servers for fault tolerance.

Zookeeper: Zookeeper is used for managing and coordinating Kafka broker nodes. It keeps track of the status of the Kafka cluster nodes and Kafka topics, partitions etc.

8.
As a distributed system, Kafka runs in a cluster, and each container in the cluster is called a broker. Partitioning is what enables messages to be split in parallel across several brokers in the cluster. Using this method of parallelism, Kafka scales to support multiple consumers and producers simultaneously

9.
Zookeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. In the context of Apache Kafka, Zookeeper plays a pivotal role in the operation of the Kafka cluster.

10.
Yes, you can install and run Kafka without Zookeeper. In this case, instead of storing all the metadata inside Zookeeper, all the Kafka configuration data will be stored as a separate partition within Kafka itself

11.
Kafka has the notion of leader and follower brokers. In Kafka, for each topic partition, one broker is chosen as the leader for the other brokers (the followers). One of the chief duties of the leader is to assign replication of topic partitions to the follower brokers.

12.
Topic replication in Kafka is critical for several reasons:

Fault Tolerance
Replication ensures that if a broker fails, the data is still available on other brokers. Kafka replicates each partition to a configurable number of brokers to prevent data loss.

High Availability
It enables Kafka to serve data even if a broker or a set of brokers goes down, as other brokers that have the replicas of the same data can continue to serve client requests.

Durability
By storing copies of the data on multiple brokers, Kafka ensures that the data is durable and can survive broker failures, network issues, or other system faults.

Load Balancing
Read operations can be load balanced across the replicas, allowing for higher throughput. While write operations are handled by the leader, read operations can be served by any of the follower replicas.

An in-sync replica (ISR) is a broker that has the latest data for a given partition. A leader is always an in-sync replica. A follower is an in-sync replica only if it has fully caught up to the partition it's following. In other words, it can't be behind on the latest records for a given partition.

13.
A consumer group is a set of consumers who cooperate to consume data from some topics. The partitions of all the topics are divided among the consumers in the group. As new group members arrive and old members leave, the partitions are re-assigned so that each member receives a proportional share of the partitions.

14.
Start ZooKeeper Server

1. start ZooKeeper 
bin/zookeeper-server-start.sh config/zookeeper.properties
This command starts a ZooKeeper server with the default configuration provided by Kafka.
Start Kafka Broker

2. After ZooKeeper is up and running, start the Kafka broker (server):
bin/kafka-server-start.sh config/server.properties
This starts the Kafka server with the default configuration. You can modify config/server.properties as needed for your setup.

15.
Building real-time data pipelines. For example, Kafka can be used to collect data from sensors, log files, social media platforms, and other sources, and stream it to data warehouses, machine learning platforms, and other destinations.

16.
A producer can use a partition key to direct messages to a specific partition. A partition key can be any value that can be derived from the application context. A unique device ID or a user ID will make a good partition key

17.
Partitioning takes the single topic log and breaks it into multiple logs, each of which can live on a separate node in the Kafka cluster. This way, the work of storing messages, writing new messages, and processing existing messages can be split among many nodes in the cluster.

18.
RabbitMQ sends and queues messages in a specific order. Unless a higher priority message is queued into the system, consumers receive messages in the order they were sent. Meanwhile, Kafka uses topics and partitions to queue messages. When a producer sends a message, it goes into a specific topic and partition.

19.
At most once: Messages are delivered once, and if there is a system failure, messages may be lost and are not redelivered. 
At least once: This means messages are delivered one or more times. If there is a system failure, messages are never lost, but they may be delivered more than once.
Exactly once: This is the preferred behavior in that each message is delivered once and only once. Messages are never lost or read twice even if some part of the system fails.

20.
This leads to a leader unbalance across the Kafka brokers. The cluster is in a leader-skewed state when a node is a leader for more partitions than the number of partitions/number of brokers. In order to solve this, Kafka has the facility of reassigning leaders to the preferred replicas.

21.
Both.
Producer: This could refer to any entity that provides goods or services to the mall. For example, stores within the mall are producers of products and services for shoppers. The mall management itself could be a producer of rental space and amenities for the stores.

Consumer: In a mall, consumers are the shoppers who visit the stores and purchase goods or services. They consume the retail experience provided by the mall.

22.
orders-transactions
inventory-updates
customer-feedback

23.
single broker.

25.
The offset is a simple integer number that is used by Kafka to maintain the current position of a consumer. That's it. The current offset is a pointer to the last record that Kafka has already sent to a consumer in the most recent poll. So, the consumer doesn't get the same record twice because of the current offset.
