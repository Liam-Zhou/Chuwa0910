# hw16 - micro Service

1.  list all the new annotations you learned to your annotations.md
2.  Document the microservice architecture and components/tools/dependencies
    - Api gateway: Zull/Zull2/Spring Cloud Gateway
    - Service Registry/Discovery: Eureka
    - Communication: restTemplate, Ribbon, Kafka, RabbitMQ
    - Resilience: Hystrix/Resilience4j
    - Configuration: Spring Cloud Config Server
3.  What are Resilience patterns? What is circuit breaker?
    Resilience patterns is the ability to detect failure and recover in a timely manner. It will build robust and fault-tolerant systems.  
    Circuit Breaker is a mechanism to prevent repeated calls to a failing service or component from overloading a system. 
4.  Read this article, then list the important questions, then write your answers: https://www.interviewbit.com/microservices-interview-questions/#main-features-of-microservices
5.  how to do load balance in microservice? Write a long Summary by yourself.
    a. https://www.geeksforgeeks.org/load-balancer-system-design-interview-question/
    b. https://www.fullstack.cafe/blog/load-balancing-interview-questions  
    Load balancing in microservices architecture is a crucial technique for ensuring optimal resource utilization, high availability, and efficient distribution of incoming requests across multiple service instances. Load balancers are typically positioned strategically within the microservices environment to achieve these objectives.
    They can be placed in several key locations: Between the Client Application/User and the Server; Between the Server and the Application/Job Servers; Between the Application Servers and the Cache Servers; Between the Cache Servers and the Database Servers.
    There are different types of load balancers that can be used in microservices architecture:
    - Software Load Balancers in Clients: These load balancers are integrated into client applications or user interfaces and are responsible for distributing requests to the appropriate service instances.
    - Software Load Balancers in Services: Load balancers integrated into the microservices themselves, which manage incoming requests and route them to the available service instances.
    - Hardware Load Balancers: Physical appliances designed for load balancing, often used in larger enterprise environments to handle high volumes of traffic.
    - Load balancers can generally be categorized into two primary types:
        - Layer 4 (L4) Load Balancer: L4 load balancers operate at the transport layer of the OSI model and primarily use information like IP addresses and port numbers to route traffic. They provide basic load balancing capabilities.
        - Layer 7 (L7) Load Balancer: L7 load balancers function at the application layer of the OSI model and offer advanced features, such as content-based routing and request inspection. They are capable of making more intelligent routing decisions based on application-specific information.
    To determine how to distribute requests effectively, load balancers employ various load balancing algorithms, including:
    - Round Robin: Requests are distributed in a sequential, cyclic manner to each available service instance in turn.
    - Weighted Round Robin: Similar to Round Robin but assigns different weights to service instances, allowing some to receive more requests than others.
    - Least Connection Method: Requests are directed to the service instance with the fewest active connections, distributing the load evenly.
    - Least Response Time Method: Requests are sent to the service instance that responds the fastest, minimizing response times for users.
    - Source IP Hash: Load balancers use the source IP address to consistently route requests to the same service instance, helpful for maintaining session persistence.
    In summary, load balancing is a fundamental component of microservices architecture that involves strategically placing load balancers to evenly distribute incoming traffic. These load balancers can be software or hardware-based, and they use algorithms like Round Robin and others to route requests efficiently, ensuring high availability and improved performance in a microservices environment.
6.  How to do service discovery?   
    Eureka is the most wildly used. It keeps track of all client-service applications. As every Microservice registers to Eureka, it knows all the client applications running on the different ports and IP addresses. It generally uses Spring Cloud and is not heavy on the application development
7.  What are the major components of Kafka?  
    Producer; Consumer (group); Brokers; Topic; Partitions; ZooKeeper(or other tool); Kafka Manager.
8.  What do you mean by a Partition in Kafka?  
    Each topic is divided into one or more partitions. Partitions allow Kafka to parallelize data distribution and storage. They are the basic unit of parallelism and scaling in Kafka. Messages within a partition are ordered, and each partition is replicated across multiple brokers for fault tolerance.
9.  What do you mean by zookeeper in Kafka and what are its uses?  
 Zookeeper is used for managing distributed configurations and leader election.
10. Can we use Kafka without Zookeeper?  
    Yes. Since kafka 2.8.0, Zookeeper has been replaced to metadata quorum.
11. Explain the concept of Leader and Follower in Kafka.  
    A partition is owned by a single broker in the cluster, that broker is called the leader of the partition. A replicated partition is assigned to additional brokers, they are called followers of the partition. Replication provides redundancy of messages in the partition, if there is a broker failure, one of the followers can take over leadership. All producers must connect to the leader in order to publish messages, but consumers may fetch from either the leader or one of the followers.
12. Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?  
    Topic Replication can guarantee availability and durability when individual nodes inevitably fail. ISR, as in-sync replicas, is the Replication of a certain partition. Produced messages are considered “committed” when they were written to the partition on all its in-sync replicas, and consumers can only read messages that are committed.
13. What do you understand about a consumer group in Kafka?  
    consumer group is one or more consumers that work together to consume a topic. The group ensures that each partition is only consumed by one member.
14. How do you start a Kafka server?  
    - start environment, like zookeeper;
    - start kafka server;
    - create topic;
    - create producer and consumers.
15. Tell me about some of the real-world usages of Apache Kafka.  
    Kafka can be used for collecting application and system metrics and logs. Applications of any kind publish metrics to a Kafka topic, and those metrics can be consumed by systems for monitoring and alerting. This is useful whenever the applications or log system need updated, since they are connected through kafka.
16. Describe partitioning key in Kafka.  
    Partitioning key is a piece of metadata associated with each message published to a Kafka topic. Partitioning key and a partitioner that will generate a hash of the key and map it to a specific partition. This ensures that all messages produced with the same key will get written to the same partition. The producer could also use a custom partitioner that follows other business rules for mapping messages to partitions.
17. What is the purpose of partitions in Kafka?  
    Partitions can provide redundancy, scalability, parallelism, and high throughput. 
18. Differentiate between Rabbitmq and Kafka.  
    RabbitMQ is a traditional message broker that follows the Advanced Message Queuing Protocol. It focuses on message queuing and supports various messaging patterns, including publish/subscribe and request/reply. Kafka is a distributed streaming platform that is primarily designed for event streaming and log aggregation. It is based on a publish/subscribe model but is more oriented toward real-time event streaming.  
    In conclusion, RabbitMQ is well-suited for traditional enterprise messaging use cases, such as task queuing, work distribution, and reliable message delivery. Kafka is ideal for event streaming, log aggregation, real-time analytics, and handling large volumes of event data generated by various applications and services.
19. What are the guarantees that Kafka provides?  
    - Durability and Persistence: message is available to consumer only after all in-sync replicas write certain message on disk;
    - Message Ordering: Within a partition, Kafka guarantees strict message ordering;
    - At most once: consumer offsets are committed as soon as message received, may cause message lost;
    - At lease once: consumer offsets are committed after well processed, may cause duplicate processing;
    - Exactly-Once Semantics: Kafka supports transactional messaging, which enables exactly-once message processing. Producers can send messages as part of a transaction, and consumers can process messages atomically;
    - Consumer Offset Tracking: Kafka maintains the offset of the last consumed message for each consumer. This allows consumers to resume reading from where they left off, ensuring that no messages are missed.
20. What do you mean by an unbalanced cluster in Kafka? How can you balance it?  
    unbalanced cluster is where the distribution of partitions across the brokers is uneven, resulting in some brokers being overburdened with data and requests while others are underutilized. To balance it, I can check consumer group management mechanism, reassign partitions, or add Brokers:
21. In your recent project, are you a producer or consumer or both?
22. In your recent project, Could you tell me your topic name?
23. In your recent project, How many brokers do you have? How many partitions for each topic? How many data for each topic.
24. In your recent project, which team produce what kind of event to you and your producer what kind of events?
25. What is offset?  
    The offset is a piece of metadata that Kafka adds to each message as it is produced. It is an integer value that monotonically increases. Each message in a given partition has a unique offset, and the following message has a greater offset (not necessarily consecutive). By storing the next possible offset for each partition, a consumer can stop and restart without losing its place.