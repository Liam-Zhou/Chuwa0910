# HW15 - Ke Chen - Microservice


## 1.  list all of the new annotations you learned to your annotations.md

**find in ShortQuestions file : annotations.md**




## 2.  Document the microservice architeture and components/tools/dependencies

**Document the microservice architeture:**

Flow in a Microservices Architecture:

1. An external client sends a request to the API Gateway.
2. API Gateway receives and routes the request to microservice by rules and load balancing(`Ribbon, Nginx`)
3. Microservices communicate with each other using Service Discovery(registry center)(`Eureka, ZooKeeper`)  to locate and interact with services.
4. Services interact with database(`R: MySQL, No: MongoDB, Cassandra`) , a distributed caching system(`Redis, Memcached`) and a distributed search engine(`Elasticsearch`) to store and peform CRUD operation to data
5. Services communicate asynchronously through message queues(`Kafka, RabbitMQ`) for event-driven workflows.

6. Microservices fetch their configurations (such as database connections, environment variables) from the Configuration Center (`Spring Cloud Config`).
7. Distributed logging services(`ELK stack: Elasticsearch, Logstash, Kibana`) collect and centralize logs for analysis, debugging, and auditing purposes.
8. Monitoring tools (`Prometheus, Grafana, resilience4J/Hystrix`) track and monitor the system's health, performance, and various metrics across microservices.

9. Continuous Integration/Continuous Deployment (CI/CD) pipeline (`Jenkins`) automates the build, test, and deployment process for microservices.
10. Microservices are packaged into containers (`Docker`) and orchestrated (`Kubernetes`) for efficient deployment, scaling, and management.


![Microservice Architecture](../hw16-microservice/hw16/Microservice%20Architecture%20%20.png)
![微服务技术栈](../hw16-microservice/hw16/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8A%80%E6%9C%AF%E6%A0%88.png)
![完整的微服务技术栈](../hw16-microservice/hw16/%E5%AE%8C%E6%95%B4%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8A%80%E6%9C%AF%E6%A0%88.png)


**Components, Tools, and Dependencies:**

![component in microservice architecture](../hw16-microservice/hw16/component%20in%20microservice%20architecture.png)

Here's an overview of the key components and the flow in a microservices architecture:

1. **Microservices**: Microservices are the individual components or services that make up the application. Each microservice is responsible for a specific business capability or feature. Microservices are typically developed using different technologies and can have their own databases, which is known as polyglot persistence.

2. **API Gateway**: An API gateway is a central entry point for external clients to interact with the microservices. It handles routing client requests to the appropriate microservices and can provide features like load balancing, authentication, and rate limiting.

3. **Service Discovery- Service Registry(`Eureka`)**: Microservices need to find and communicate with each other. Service discovery is a mechanism that allows microservices to locate and communicate with one another dynamically. Tools like Eureka, Consul, or Kubernetes service discovery can be used.

4. **Load Balancing(`Ribbon/Nginx`)**: Load balancing is essential to distribute incoming client requests across multiple instances of a microservice, ensuring high availability and optimal resource utilization.

5. **Authentication and Authorization**: Security is a crucial concern in microservices architecture. Each microservice should authenticate and authorize incoming requests to ensure that only authorized clients can access specific services.

6. **Communication Protocols(`Kafka`)**: Microservices often communicate with each other using lightweight protocols like HTTP/HTTPS, gRPC, or message queues such as RabbitMQ or Kafka.

7. **Data Storage(`R: MySQL, No: MongoDB, Cassandra`)**: Each microservice can have its own data store, which can be a relational database, NoSQL database, or other data storage solutions. Data storage choices are made based on the specific needs of the microservice.

8. **Monitoring and Logging(`resilience4J/Hystrix`)**: Monitoring and logging are essential for tracking the health and performance of microservices. Tools like Prometheus, Grafana, ELK Stack, or centralized logging systems are used to collect and analyze data.

9. **Containerization(`Docker`)**: Many microservices are deployed as containers using technologies like Docker. Containerization provides a consistent environment for development and production.

10. **Orchestration(`Kubernetes`)**: Container orchestration platforms like Kubernetes are often used to manage and deploy microservices. They offer features for scaling, load balancing, and fault tolerance.




## 3.  What are Resilience patterns? What is circuit breaker?

**What are Resilience patterns?**

Resilience patterns are <u>a set of practices and strategies that are designed to ensure that a system can continue to operate and provide a certain level of service, even in the presence of failures or unexpected issues.</u>

For resilience, a library like `Hystrix`(no longer actively by Netflix)/`Resilience4j`(modern and actively maintained) can be useful.

Hystrix is a library developed by Netflix that implements the circuit breaker pattern Spring Cloud offers an integration and further simplification for Hystrix.

Why using Hystrix:
When one service calls another, but the another service has a problem, Hystrix can catch all problems of underlying services and process a fallback plan.

**What is circuit breaker?**

<u>circuit breaker is used to handle faults and failures in distributed systems</u>

<u>If a system call results in an error, the circuit breaker switch to: open state and temporarily does not allow any calls to pass through to the failing service or component.</u>

- The circuit breaker can be in one of three states: `Closed` (normal operation), `Open` (preventing interactions), or `Half-Open` (testing to see if the service has recovered).

![Circuit breaker](../hw16-microservice/hw16/Circuit%20breaker.png)




## 4.  Read this article, then list the important questions, then write your answers 
- a. https://www.interviewbit.com/microservices-interview-questions/#main-features-of-microservices

1. Write main features of Microservices.
2. Write main components of Microservices.
3. What are the benefits and drawbacks of Microservices?
4. Name three common tools mostly used for microservices.
5. Explain the working of Microservice Architecture.
6. Write difference between Monolithic, SOA and Microservices Architecture.
7. Explain spring cloud and spring boot.
8. What is the role of actuator in spring boot?
9. Explain how you can override the default properties of Spring boot projects.
10. What issues are generally solved by spring clouds?
11. What do you mean by Cohesion and Coupling?
12. What do you mean by Bounded Context?
13. Write the fundamental characteristics of Microservice Design.
14. What are the challenges that one has to face while using Microservices?
15. Explain PACT in microservices.
16. Explain how independent microservices communicate with each other.
17. What do you mean by client certificates?
18. Explain CDC.
19. Name some famous companies that use Microservice architecture.
20. What do you mean by Domain driven design?
21. Explain OAuth.
22. Explain the term Eureka in Microservices.




## 5.  how to do load balance in microservice? Write a long Summary by yourself.

Load Balancer – System Design Interview Question:
   - https://www.geeksforgeeks.org/load-balancer-system-design-interview-question/

20 Load Balancing Interview Questions For System Design Interview:
   - https://www.fullstack.cafe/blog/load-balancing-interview-questions


A load balancer <u>distribute client requests across all servers or cluster, such as Ribbon, Nginx</u>

Ribbon is a client-side load balancer provided by Netflix that works within the microservices ecosystem. It operates at the client-side of the service consumer and helps distribute the load across multiple instances of a service. When a client application makes a request, Ribbon intercepts it and decides which instance of the service to send the request to based on predefined load balancing algorithms like Round Robin, Random, Weighted Response Time, etc. The configuration for Ribbon typically resides with the client application, allowing for flexibility and customization.

NGINX is a powerful and versatile open-source reverse proxy server that can also be used as a load balancer. It operates as an intermediary between the client and the backend services. NGINX receives incoming requests from clients and then routes these requests to different backend service instances based on predefined rules and algorithms. NGINX offers features like HTTP and TCP load balancing, health checks, session persistence, and more. Its configuration is typically managed at the server level and provides a centralized point for load balancing multiple services.




## 6.  How to do service discovery?

1. choose one regisrty service such as Eureka to configure Eureka

2. register microservices as Eureka Clients in configuration file, when a microservice starts up, the Eureka Client automatically registers with the Eureka Server.

3. The microservice sends heartbeat signals periodically to the Eureka Server to confirm its availability.

4. Eureka Server maintains a registry of all registered services and their instances, enabling clients to discover and communicate with them.

5. If a service instance becomes unavailable or fails, Eureka Server removes that instance from its registry beacuse continuously monitors




## 7. What are the major components of Kafka?

Kafka : https://www.conduktor.io/kafka/kafka-topics/

- `Producers`: Applications to send data into topics

- `Consumers`: Applications to read data from Kafka topics

- `Topic`: to organize related messages. 
   - For example, we may have a topic called orders that may contain order data from our application.

- `Partitions`: topics are broken down into a number of partitions.

- `Consumer Groups`: a group of consumer to consume different partitions in a topic.

- `offset`: represent the position of a message within a Kafka Partition.

- `Consumer Offsets`: keeps track of what messages a given consumer group last successfully processed.

- `broker`: A single Kafka server is called a Kafka Broker
   - That Kafka broker is a program that runs on the Java Virtual Machine (Java version 11+) and usually a server that is meant to be a Kafka broker will solely run the necessary program and nothing else.

- `Kafka Partitions Leader and Replicas`: 
   - leader: one broker to send and receive data to client
   - replica(ISR): store replicated data for client

- `Zookepper((previously a major component, but now deprecated in newer Kafka versions))`: 
   - Zookeeper keeps track of which brokers are part of the Kafka cluster
   - Zookeeper is used by Kafka brokers to determine which broker is the leader of a given partition and topic and perform leader elections
   - Zookeeper stores configurations for topics and permissions
   - Zookeeper sends notifications to Kafka in case of changes (e.g. new topic, broker dies, broker comes up, delete topics, etc.…)

- `KRaft Mode`;
   - to replace Zookepper.




## 8.  What do you mean by a Partition in Kafka?

partition is <u>a subset of the total data stream for a topic, topic break down into partition.</u>




## 9.  What do you mean by zookeeper in Kafka and what are its uses?

**What do you mean by zookeeper:**

zookeeper is a component for client and Kafka brokers to keep track of all the Kafka brokers.

**what are its uses:**

- Zookeeper keeps track of which brokers are part of the Kafka cluster
- Zookeeper is used by Kafka brokers to determine which broker is the leader of a given partition and topic and perform leader elections
- Zookeeper stores configurations for topics and permissions
- Zookeeper sends notifications to Kafka in case of changes (e.g. new topic, broker dies, broker comes up, delete topics, etc.…)




## 10. Can we use Kafka without Zookeeper?

<u>Yes, zookeeper was replaced by KRaft((Kafka Raft Metadata mode).</u>




## 11. Explain the concept of Leader and Follower in Kafka.

leader: one broker is responsible for sending and receiving data to client.
replica(ISR): a topic-partition is responsible for storing replicated data for leader.




## 12. Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?

**Why is Topic Replication important in Kafka?**

because of resilience that offer in the face of failures.

Data Replication helps prevent data loss by writing the same data to more than one broker. It has the leader and replica broker to prevent data loss by writing the same data to more than one broker.


**what is ISR:**

ISR: is stand for In-Sync Replica, are replicas for leader and are in sync with the leader for a partition




## 13. What do you understand about a consumer group in Kafka?

a group of consumers that from the same application and therefore performing the same "logical job".




## 14. How do you start a Kafka server?

<u>by using command: kafka-server-start.sh config/server.properties(kafka server configuration file)</u>


Starting Kafka: https://www.conduktor.io/kafka/starting-kafka/

start a Kafka server on mac without Zookeeper

1. generate a new ID for the cluster. This returns a UUID

```
~/kafka_2.13-3.0.0/bin/kafka-storage.sh random-uuid
```

2. format the storage directory

```
~/kafka_2.13-3.0.0/bin/kafka-storage.sh format -t <uuid> -c ~/kafka_2.13-3.0.0/config/kraft/server.properties
```

This will format the directory that is in the log.dirs in the config/kraft/server.properties file (by default /tmp/kraft-combined-logs)

3. luanch the broker itself in darmon mode by running:
```
~/kafka_2.13-3.0.0/bin/kafka-server-start.sh ~/kafka_2.13-3.0.0/config/kraft/server.properties
```


Kafka CLI Tutorials: https://www.conduktor.io/kafka/kafka-cli-tutorial/

1. install and start kafka with KRaft(without zookeeper) on host or use Docker to start

2. using Kafka CLI(Command Line Interface) operate topic, consumer, producer, consumers in group, consumer group and connection.
   - Kafka Topic CLI: create, delete, describe or change a topic
   - Kafka Producer CLI: read data from standard input and publish it to Kafka
   - Kafka Consumer CLI: read data from Kafka and output it to standard output
   - Kafka Consumers in Group CLI: consumers in a consumer group work using Kafka console consumer CLI
   - Kafka Consumer Group Management CLI: manage consumer groups in Kafka
   - Kafka Connect CLI: how to leverage Kafka Connect connectors with connect-standalone to write data into Kafka.




## 15. Tell me about some of the real-world usages of Apache Kafka.

Kafka could do <u>messaging for microservices, website activity tracking, and operational metrics, such as send and receive messages, generate real-time financial alerts, and predict advertising budgeting</u> 




## 16. Describe partitioning key in Kafka.

partitioning key is also known as message key. Each event message contains an optional key and a value. 

if the key is null, by the producer, messages are sent in a round-robin way.

if the key is not null, messages with the same key will always be sent and stored in the same partition. 




## 17.  What is the purpose of partitions in Kafka?

1. distribute the load and allow Kafka to handle larger amounts of data by leveraging multiple servers.
2. facilitate concurrent processing
3. to face of failures by using leader and replicas.




## 18. Differentiate between Rabbitmq and Kafka.

1. Messaging protocols
   - Kafka: use a custom binary protocol over TCP
   - RabbitMQ: a AMQP (Advanced Message Queuing Protocol) used by queues

2. Message ordering
   - Kafka: in the order of FIFO(先进先出) if there is only one consumer
   - RabbitMQ: in the order of LIFO(后进先出) if there is only one consumer

3. Exactly-once semantics
   - Kafka: supports exactly-once semantics
   - RabbitMQ: support at-most-once semantics.

4.  Message priorities
- Kafka: No message priority support.
- RabbitMQ: support message priority and sent these messages to a priority queue.




## 19. What are the guarantees that Kafka provides?

1. messagers are appended to a topic-partition in the order they are sent
2. Consumers read messages in the order stored in a topic-partition
3. with a replication factor of N, producers and consumers can tolerate up ti N-1 brokers being down
4. a replication factor of 3 is a good idea:
   - allows for one broker to be taken down for maintenance
   - allows for another broker to be taken down unexpectedly
5. as long as the number of partitions remains constant for a topic(no new partitions), the same key will always go to the same partition.




## 20. What do you mean by an unbalanced cluster in Kafka? How can you balance it?

**What do you mean by an unbalanced cluster in Kafka?**

An unbalanced cluster is <u>a situation where the distribution of data, partitions, or workload across the brokers in the Kafka cluster is uneven. For exmaple: unbalanced cluster means having more consumers than partitions, some consumers will be inactive.</u>


**How can you balance it?**

reassign partitions, adjust topic configurations, add or remove brokers, and ensure uniform consumer load across partitions.




## 21. In your recent project, are you a producer or consumer or both?

both. I produce events related to customer purchases and preferences while also consuming data for analytics and personalized recommendations.




## 22. In your recent project, Could you tell me your topic name?

mall_transactions



## 23. In your recent project, How many brokers do you have? How many partitions for each topic? How many data for each topic.

- Number of Brokers: The Kafka cluster might consist of 3 brokers to handle the incoming stream of data efficiently.
- Partitions for the Topic: To handle the load, the "mall_transactions" topic might be set up with 10 partitions to allow for parallel processing and scalability.
- Volume of Data: Considering the volume of data, let's assume that each partition stores approximately 1 million records per day. So, with 10 partitions, it would accumulate around 10 million records daily.




## 24. In your recent project, which team produce what kind of event to you and you producer what kind of events?

- Producing Teams and Event Types: Various teams in the mall contribute to event production:
Sales Team: Produces purchase events like "item purchased," "payment made," "receipt generated."
Customer Service Team: Produces events related to customer feedback, such as "customer satisfaction survey submitted," "complaint registered."
- Marketing Team: Generates events related to promotional activities like "coupon redeemed," "discount applied."
Inventory Management Team: Produces events like "stock replenished," "item restocked."
AI Assistant (Producer) Events: As an AI assistant acting as a producer:
I generate events related to customer behavior such as "customer browsing behavior," "product interest shown," "recommended items based on purchase history."
I might also produce events related to system health and performance, like "Kafka cluster status update," "analytics dashboard update."




## 25. What is offset?

an offset <u>represent the position of a message within a Kafka Partition.</u>